{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "friendly-invasion",
   "metadata": {},
   "source": [
    "# Multiple convolution layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fiscal-receptor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import convolution layers in 2-Dimensional image\n",
    "from keras.layers import Conv2D\n",
    "\n",
    "# Use a Flatten layer to be like a bridge between a convolution layer and a dense layer\n",
    "from keras.layers import Flatten\n",
    "\n",
    "# Other modules are the same\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential    # 仍然使用Sequential model\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fatal-testament",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# first cnn layer\n",
    "model.add(Conv2D(10, kernel_size = 2, activation = 'relu', input_shape = (28, 28, 1), padding = 'same'))\n",
    "\n",
    "# second cnn layer\n",
    "model.add(Conv2D(10, kernel_size = 2, activation = 'relu'))\n",
    "\n",
    "# Flatten layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-craft",
   "metadata": {},
   "source": [
    "# Why adding multiple CNN layers?\n",
    "\n",
    "An example of multiple CNN\n",
    "![](Image/Image10.jpg)\n",
    "\n",
    "1. Layers in the early part of the network tend to respond to oriented lines or **simple textures**.\n",
    "2. Intermediate layers of the network tend to respond to **more complex** features including simple objects, such as eyes.\n",
    "3. For higher layers of the network, the feature maps tend to extract **specific types of objects**, such as dogs, cats and cars.\n",
    "\n",
    "Therefore, we can build up objects in an image from simple features to more complex features and distinct categories of objects\n",
    "\n",
    "However, a very deep CNN requires more time and data to train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-adobe",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-luther",
   "metadata": {},
   "source": [
    "# Consideration of the number of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-outdoors",
   "metadata": {},
   "source": [
    "## Comparing dense network and convolution network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-child",
   "metadata": {},
   "source": [
    "### A fully connected network (Dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "automated-funds",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# first cnn layer\n",
    "model.add(Dense(10, activation = 'relu', input_shape = (784, )))\n",
    "\n",
    "# second cnn layer\n",
    "model.add(Dense(10, activation = 'relu'))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "resistant-technique",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 7,993\n",
      "Trainable params: 7,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# summarise the model to check number of parameters\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "similar-welsh",
   "metadata": {},
   "source": [
    "第一層：784個pixels * 10個neurons + 10個bias units = 7850 <br/>\n",
    "第二層：第一層的10個neurons * 10個neurons + 10個bias units = 110 <br/>\n",
    "第三層：第二層的10個neurons * 3個neurons + 3個bias units = 33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-skirt",
   "metadata": {},
   "source": [
    "### A convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "listed-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# first cnn layer\n",
    "model.add(Conv2D(10, kernel_size = 3, activation = 'relu', input_shape = (28, 28, 1), padding = 'same'))\n",
    "\n",
    "# second cnn layer\n",
    "model.add(Conv2D(10, kernel_size = 3, activation = 'relu', padding = 'same'))\n",
    "\n",
    "# Flatten layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ordered-vessel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 10)        100       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 10)        910       \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 7840)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 23523     \n",
      "=================================================================\n",
      "Total params: 24,533\n",
      "Trainable params: 24,533\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-bathroom",
   "metadata": {},
   "source": [
    "第一層：10個kernels * Kernel_Size為(3 * 3) + 10個bias units = 100 <br/>\n",
    "第二層：前一層10個kernels * 這一層10個kernels * 每個kernel的總pixels為(3 * 3) + 10個bias units = 910 <br/>\n",
    "第三層：Flatten沒有參數，只會將第二層的10個feature map合併成一個Array <br/>\n",
    "第四層：由於第一層與第二層都有zero padding，因此出來的每一個feature map的size都跟原來的一樣(784 pixels)，而第二層傳出10個feature maps，因此有784 * 10個變量。然後第四層有3個neurons，因此第四層的參數總數為 $784 * 10 * 3 + 3個bias = 23523$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-gregory",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-aruba",
   "metadata": {},
   "source": [
    "## Another example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-turner",
   "metadata": {},
   "source": [
    "### A dense network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "funded-anaheim",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# first cnn layer\n",
    "model.add(Dense(5, activation = 'relu', input_shape = (784, )))\n",
    "\n",
    "# second cnn layer\n",
    "model.add(Dense(15, activation = 'relu'))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "higher-section",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 5)                 3925      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 15)                90        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 3)                 48        \n",
      "=================================================================\n",
      "Total params: 4,063\n",
      "Trainable params: 4,063\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-combining",
   "metadata": {},
   "source": [
    "### A convolutional network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "controlled-junction",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# first cnn layer\n",
    "model.add(Conv2D(5, kernel_size = 3, activation = 'relu', input_shape = (28, 28, 1), padding = 'same'))\n",
    "\n",
    "# second cnn layer\n",
    "model.add(Conv2D(15, kernel_size = 3, activation = 'relu', padding = 'same'))\n",
    "\n",
    "# Flatten layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "agreed-academy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 5)         50        \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 15)        690       \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 11760)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 35283     \n",
      "=================================================================\n",
      "Total params: 36,023\n",
      "Trainable params: 36,023\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-anthony",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "A dense network tends to have more parameters at the first layer, while a convolutional network tends to have more parameters at the output layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-cleaners",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-polish",
   "metadata": {},
   "source": [
    "# Pooling operations\n",
    "\n",
    "A large number of parameters of the convolutional network can be a challenge. Summarizing the output of convolutional layers in concise manner is a way to mitigate this problem, and it's called **\"Pooling\"** (是一種資訊壓縮的概念)\n",
    "\n",
    "1.  Max Pooling: <br/>\n",
    "假設有一張28 * 28的image，今天我用一個2 * 2的window來壓縮。一開始，該window位於image的最左上角，擷取到最左上角2 * 2這塊區域的4個pixels的值。然後將整塊區域用這4個pixels中最大的值取代，使左上角這四個pixels的數值都是原本四個的最大值，等於四個合而為一，並保留最大值。一直重複相同的步驟直到window掃完整張image，這時資料的大小會變成原本的$1/4$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developmental-wireless",
   "metadata": {},
   "source": [
    "### Step-by-step Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "graduate-strengthening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-a296a41aa72e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Keep moving our window\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;31m# Until we have done the first two rows of the image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2704\u001b[0m     \"\"\"\n\u001b[0;32m   2705\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[1;32m-> 2706\u001b[1;33m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[0;32m   2707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "# Allocating the output (consider the size of the window is 2*2)\n",
    "im = np.array([[1,0,1,1], \n",
    "              [1,0,0,1], \n",
    "              [0,0,1,1], \n",
    "              [1,0,0,0]])\n",
    "\n",
    "result = np.zeros((int(im.shape[0]/2), int(im.shape[1]/2)))\n",
    "\n",
    "# First, 左上角第一個對應image左上角四個\n",
    "result[0, 0] = np.max(im[0:2, 0:2])\n",
    "\n",
    "# Second, window向右移動兩個pixels(不重複計算)\n",
    "result[0, 1] = np.max(im[0:2, 2:4])\n",
    "\n",
    "# Keep moving our window\n",
    "result[0, 2] = np.max(im[0:2, 4:6])\n",
    "# Until we have done the first two rows of the image\n",
    "\n",
    "# Then start over at the second row of the result\n",
    "result[1, 0] = np.max(im[2:4, 0:2])\n",
    "result[1, 1] = np.max(im[2:4, 2:4])\n",
    "result[1, 2] = np.max(im[2:4, 4:6])\n",
    "\n",
    "# Until we have gone through every pixel of the image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-melissa",
   "metadata": {},
   "source": [
    "### Loop Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "respective-print",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = np.array([[1,0,1,1], \n",
    "              [1,0,0,1], \n",
    "              [0,0,1,1], \n",
    "              [0,0,0,0]])\n",
    "\n",
    "result = np.zeros((int(im.shape[0]/2), int(im.shape[1]/2)))\n",
    "for i in range(result.shape[0]):\n",
    "    for j in range(result.shape[1]):\n",
    "        result[i, j] = np.max(im[2*i:2*i+2, 2*j:2*j+2])\n",
    "        \n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-october",
   "metadata": {},
   "source": [
    "## Max Pooling in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "trying-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import MaxPool2D for max pooling\n",
    "from keras.layers import MaxPool2D\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "surprising-quick",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build our network just like before\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(5, kernel_size = 3, activation = 'relu', input_shape = (28, 28, 1)))\n",
    "\n",
    "# After each convolutional layer, we add a POOLING layer (argument 2 means window size = 2)\n",
    "model.add(MaxPool2D(2))\n",
    "\n",
    "# second convolutional layer\n",
    "model.add(Conv2D(15, kernel_size = 3, activation = 'relu', padding = 'same'))\n",
    "\n",
    "# After each convolutional layer, we add a POOLING layer (argument 2 means window size = 2)\n",
    "model.add(MaxPool2D(2))\n",
    "\n",
    "# The rest of layers are the same\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "posted-american",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 26, 26, 5)         50        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 5)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 13, 13, 15)        690       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 15)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 540)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 3)                 1623      \n",
      "=================================================================\n",
      "Total params: 2,363\n",
      "Trainable params: 2,363\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-style",
   "metadata": {},
   "source": [
    "**According to the result, the number of parameters of the model dramatically decreases.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
