{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "marked-gasoline",
   "metadata": {},
   "source": [
    "# Convolution in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-prevention",
   "metadata": {},
   "source": [
    "Compared to Dense layers, **which having every neuron in a layer connected to every neuron in the previous layer**, Convolution layers connect to the previous by **kernels**.\n",
    "\n",
    "Therefore, there are fewer weights in CNNs\n",
    "\n",
    "例如，Dense層有50個neurons，前一層也有50個neurons，則總共有2500個weights <br/>\n",
    "而假設我一層*Conv2D*中的kernel_size設為3，則代表這一層的每個neurons只會連到前一層的9個neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pending-globe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import convolution layers in 2-Dimensional image\n",
    "from keras.layers import Conv2D\n",
    "\n",
    "# Use a Flatten layer to be like a bridge between a convolution layer and a dense layer\n",
    "from keras.layers import Flatten\n",
    "\n",
    "# Other modules are the same\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential    # 仍然使用Sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-continuity",
   "metadata": {},
   "source": [
    "Flatten layers 可將 Kernels 跑出的 **Feature Maps** flatten into **arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cooked-exclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-member",
   "metadata": {},
   "source": [
    "## Example 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-deviation",
   "metadata": {},
   "source": [
    "### Import and process training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "increased-arcade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Import the independent variables of the training data\n",
    "import gzip\n",
    "f = gzip.open('MNIST dataset/Training/train-images-idx3-ubyte.gz','r')\n",
    "\n",
    "image_size = 28\n",
    "num_images = 5000\n",
    "\n",
    "f.read(16)\n",
    "buf = f.read(image_size * image_size * num_images)\n",
    "X_train = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "X_train = X_train.reshape(num_images, image_size, image_size, 1)\n",
    "print(X_train.shape)\n",
    "# X_train[10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "willing-weekly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image = np.asarray(X_train[1]).squeeze()\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "becoming-filename",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,)\n",
      "[1. 4. 3. 5. 3. 6. 1. 7. 2. 8.]\n"
     ]
    }
   ],
   "source": [
    "# Import the labels of the training data\n",
    "import gzip\n",
    "f = gzip.open('MNIST dataset/Training/train-labels-idx1-ubyte.gz','r')\n",
    "\n",
    "num_images = 5000\n",
    "\n",
    "f.read(16)\n",
    "buf = f.read(num_images)\n",
    "y_train = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "print(y_train.shape)\n",
    "print(y_train[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-calvin",
   "metadata": {},
   "source": [
    "### Converting the labels into dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "annual-tooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Function =====\n",
    "def dummies(n, labels):\n",
    "    # The number of image categories\n",
    "    n_categories = n\n",
    "\n",
    "    # The unique values of categories in the data\n",
    "    categories = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "    # Initialize ohe_labels as all zeros\n",
    "    ohe_labels = np.zeros((len(labels), n_categories))\n",
    "\n",
    "    # Loop over the labels\n",
    "    for ii in range(len(labels)):\n",
    "        # Find the location of this label in the categories variable\n",
    "        jj = np.where(labels[ii] == categories)\n",
    "        # Set the corresponding zero to one\n",
    "        ohe_labels[ii,jj] = 1\n",
    "\n",
    "    return ohe_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "wrapped-option",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = dummies(10, y_train)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-blind",
   "metadata": {},
   "source": [
    "### Import and process testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fleet-collar",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Import the independent variables of the testing data\n",
    "f = gzip.open('MNIST dataset/Validating/t10k-images-idx3-ubyte.gz','r')\n",
    "\n",
    "image_size = 28\n",
    "num_images = 2000\n",
    "\n",
    "f.read(16)\n",
    "buf = f.read(image_size * image_size * num_images)\n",
    "X_test = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "X_test = X_test.reshape(num_images, image_size, image_size, 1)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "upper-inventory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAANzUlEQVR4nO3df6zV9X3H8dcL5IdFVBiMMSRaLMRiF6G9oXV1m8a1s/xRbLK5ks5hY3O7rG5tQtIat6Q2/RGzVN2WNV1oJaWLP+L8UVlqOpHaOFuCXhwFhLZQhyvsChJuB24ZcK/v/XG/NFe93++5nPM9P+T9fCQ355zv+3y/33eOvvie8/2c7/k4IgTg7Dep2w0A6AzCDiRB2IEkCDuQBGEHkjinkzub6mkxXTM6uUsglf/T/+hknPB4tZbCbvs6SX8nabKkb0bEHVXPn64Zeq+vbWWXACpsjc2ltabfxtueLOlrkj4kaamk1baXNrs9AO3Vymf2FZL2RcSLEXFS0gOSVtXTFoC6tRL2BZJ+MebxgWLZ69jutz1ge+CUTrSwOwCtaPvZ+IhYFxF9EdE3RdPavTsAJVoJ+0FJC8c8vqhYBqAHtRL25yQttv1221MlfVTSxnraAlC3pofeImLY9i2S/lWjQ2/rI+KF2joDUKuWxtkj4nFJj9fUC4A24uuyQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4k0dGfkkZz9n/pysr6yPTyyTnnXv5K5bpbrni4qZ5Ou/T7H6+sz3z23NLavL//UUv7xpnhyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTDO3gOGvru4sr5r2T+0bd+nyofoJ+Qn13yzsn5v3/zS2oObfq9y3ZE9e5vqCePjyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTDO3gGNxtF/uOyBtu37H3+5qLJ+15YPVNYvubj6evgnlj5SWf/YzMHS2pdvmlO57qLPMc5ep5bCbnu/pOOSRiQNR0RfHU0BqF8dR/ZrIuJIDdsB0EZ8ZgeSaDXsIekJ29ts94/3BNv9tgdsD5zSiRZ3B6BZrb6NvyoiDtr+dUmbbP8kIp4e+4SIWCdpnSSd79ktXnYBoFktHdkj4mBxe1jSo5JW1NEUgPo1HXbbM2zPPH1f0gcl7aqrMQD1auVt/DxJj9o+vZ37IuJ7tXT1FjN87Xsq69+/4msNtjClsvq3Q0sq60/9ccWI538drlx3ydBAZX3S9OmV9a9s/a3K+m1zdpbWhmcNV66LejUd9oh4UdIVNfYCoI0YegOSIOxAEoQdSIKwA0kQdiAJLnGtwasLplbWJzX4N7XR0NoPPlw9vDXy4k8r663Y94XllfX7Zt/ZYAvTSisXfY9jTSfxagNJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoyz1+DCb2+prP/hwJ9U1j10rLI+PLj/TFuqzSdWPllZP29S+Tg6egtHdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2DhjZ/bNut1Bq/5evrKzffOFXG2yh+qem1w6+r7Q288k9leuONNgzzgxHdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgnH2s9wvb6weR//hn1aPo18wqXocfcuJyZX17V8q/935c489W7ku6tXwyG57ve3DtneNWTbb9ibbe4vbWe1tE0CrJvI2/luSrnvDslslbY6IxZI2F48B9LCGYY+IpyUdfcPiVZI2FPc3SLq+3rYA1K3Zz+zzImKwuP+ypHllT7TdL6lfkqbrbU3uDkCrWj4bHxEhKSrq6yKiLyL6plRM8gegvZoN+yHb8yWpuD1cX0sA2qHZsG+UtKa4v0bSY/W0A6BdGn5mt32/pKslzbF9QNLnJd0h6UHbN0t6SdIN7WwSzTvy7tJPWJIaj6M3suYHn6isL/kOY+m9omHYI2J1SenamnsB0EZ8XRZIgrADSRB2IAnCDiRB2IEkuMT1LHBy08WltS2X3dlg7eqhtyu2rKmsv3Ptzyvr/Bx07+DIDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJMM7+FnDOoksq6198xz+X1mY1uIR124nqfV/8xeqR8pGhoeoNoGdwZAeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnfwu49MGDlfXlU5v/N3v15j+rrC/58XNNbxu9hSM7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOHsPGFpzZWX9C/Ma/fb7tNLKmv2/X7nmOz+7r7LO776fPRoe2W2vt33Y9q4xy263fdD29uJvZXvbBNCqibyN/5ak68ZZfndELCv+Hq+3LQB1axj2iHha0tEO9AKgjVo5QXeL7R3F2/xZZU+y3W97wPbAKTX4wTMAbdNs2L8u6VJJyyQNSio9gxQR6yKiLyL6plScSALQXk2FPSIORcRIRLwm6RuSVtTbFoC6NRV22/PHPPyIpF1lzwXQGxqOs9u+X9LVkubYPiDp85Kutr1MUkjaL+mT7Wvxre+cBb9ZWf+dv9xaWT9vUvMff7bsfkdlfckQ16tn0TDsEbF6nMX3tKEXAG3E12WBJAg7kARhB5Ig7EAShB1IgktcO2DPbQsr69/5jX9pafvX7Pyj0hqXsOI0juxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7B2w7cN3N3hGa7/gc8Gfv1ZaGx4aamnbOHtwZAeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnPwucmndBaW3KyQUd7OTNRl45UlqLE9XTgXla9fcPJs+d01RPkjQy98LK+t61U5ve9kTEiEtrl/1Fg98gOHasqX1yZAeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJBhnPwt896H13W6h1G//+3iTAI86cuj8ynVnzT1eWd/6nvua6qnXLf3rWyrriz67pantNjyy215o+ynbu22/YPvTxfLZtjfZ3lvczmqqAwAdMZG38cOS1kbEUknvk/Qp20sl3Sppc0QslrS5eAygRzUMe0QMRsTzxf3jkvZIWiBplaQNxdM2SLq+TT0CqMEZfWa3fYmk5ZK2SpoXEYNF6WVJ80rW6ZfUL0nT9bamGwXQmgmfjbd9nqSHJX0mIl73TfyICEkx3noRsS4i+iKib0qLP6wIoHkTCrvtKRoN+r0R8Uix+JDt+UV9vqTD7WkRQB0avo23bUn3SNoTEXeNKW2UtEbSHcXtY23p8CywavfHKuub3/VQhzrpvB8tv79r+/7fOFlaOxXlP789ESt33FRZ/+/tzV9+u+CZ4abXrTKRz+zvl3SjpJ22txfLbtNoyB+0fbOklyTd0JYOAdSiYdgj4hlJZVfaX1tvOwDaha/LAkkQdiAJwg4kQdiBJAg7kASXuHbAuX/wH5X1y79SfUljtPG/0szLjlbW23kZ6eX/9vHKevznjJa2v+ihV8uLz+5saduztLelejdwZAeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJDz6IzOdcb5nx3vNhXJAu2yNzToWR8e9SpUjO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTRMOy2F9p+yvZu2y/Y/nSx/HbbB21vL/5Wtr9dAM2ayPQDw5LWRsTztmdK2mZ7U1G7OyK+2r72ANRlIvOzD0oaLO4ft71H0oJ2NwagXmf0md32JZKWS9paLLrF9g7b623PKlmn3/aA7YFTOtFatwCaNuGw2z5P0sOSPhMRxyR9XdKlkpZp9Mh/53jrRcS6iOiLiL4pmtZ6xwCaMqGw256i0aDfGxGPSFJEHIqIkYh4TdI3JK1oX5sAWjWRs/GWdI+kPRFx15jl88c87SOSdtXfHoC6TORs/Psl3Shpp+3txbLbJK22vUxSSNov6ZNt6A9ATSZyNv4ZSeP9DvXj9bcDoF34Bh2QBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJR0Tndma/IumlMYvmSDrSsQbOTK/21qt9SfTWrDp7uzgi5o5X6GjY37RzeyAi+rrWQIVe7a1X+5LorVmd6o238UAShB1IotthX9fl/Vfp1d56tS+J3prVkd66+pkdQOd0+8gOoEMIO5BEV8Ju+zrbP7W9z/at3eihjO39tncW01APdLmX9bYP2941Ztls25ts7y1ux51jr0u99cQ03hXTjHf1tev29Ocd/8xue7Kkn0n6gKQDkp6TtDoidne0kRK290vqi4iufwHD9u9KelXStyPiXcWyv5F0NCLuKP6hnBURn+uR3m6X9Gq3p/EuZiuaP3aacUnXS7pJXXztKvq6QR143bpxZF8haV9EvBgRJyU9IGlVF/roeRHxtKSjb1i8StKG4v4Gjf7P0nElvfWEiBiMiOeL+8clnZ5mvKuvXUVfHdGNsC+Q9Isxjw+ot+Z7D0lP2N5mu7/bzYxjXkQMFvdfljSvm82Mo+E03p30hmnGe+a1a2b681Zxgu7NroqId0v6kKRPFW9Xe1KMfgbrpbHTCU3j3SnjTDP+K9187Zqd/rxV3Qj7QUkLxzy+qFjWEyLiYHF7WNKj6r2pqA+dnkG3uD3c5X5+pZem8R5vmnH1wGvXzenPuxH25yQttv1221MlfVTSxi708Sa2ZxQnTmR7hqQPqvemot4oaU1xf42kx7rYy+v0yjTeZdOMq8uvXdenP4+Ijv9JWqnRM/I/l/RX3eihpK9Fkn5c/L3Q7d4k3a/Rt3WnNHpu42ZJvyZps6S9kp6UNLuHevsnSTsl7dBosOZ3qberNPoWfYek7cXfym6/dhV9deR14+uyQBKcoAOSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJP4fcKgKSCYRzXYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image = np.asarray(X_test[1]).squeeze()\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "respective-logic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,)\n",
      "[5. 9. 0. 6. 9. 0. 1. 5. 9. 7.]\n"
     ]
    }
   ],
   "source": [
    "# Import the labels of the testing data\n",
    "import gzip\n",
    "f = gzip.open('MNIST dataset/Validating/t10k-labels-idx1-ubyte.gz','r')\n",
    "\n",
    "num_images = 2000\n",
    "\n",
    "f.read(16)\n",
    "buf = f.read(num_images)\n",
    "y_test = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "print(y_test.shape)\n",
    "print(y_test[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-dictionary",
   "metadata": {},
   "source": [
    "### A simpler way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "entertaining-admission",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAOk0lEQVR4nO3df5BV5X3H8c8HXEDwR0TihiKNSogpTSvqVtLGdjSajJq0aHQcSWtoa7u01RqtJnXsH/pPp04bNIlNbDHSoJPoODGOTMI0Uoylji2yKuWHRjEWI5sVtIyCNsKyfvvHHpyN7nnues/9xT7v18zOvfd877nn6x0+nnPPc+59HBECMP5NaHcDAFqDsAOZIOxAJgg7kAnCDmTikFZubJInxxRNa+Umgay8qTe0L/Z6tFqlsNs+R9JXJU2U9M2IuCn1/CmapgU+q8omASSsizWltboP421PlPR1SedKmidpke159b4egOaq8pn9NEnPRcTzEbFP0j2SFjamLQCNViXssyS9OOLx9mLZL7Dda7vPdt+g9lbYHIAqmn42PiKWRURPRPR0aXKzNwegRJWw90uaPeLxscUyAB2oStjXS5pr+3jbkyRdImllY9oC0Gh1D71FxH7bV0j6oYaH3pZHxJaGdQagoSqNs0fEKkmrGtQLgCbiclkgE4QdyARhBzJB2IFMEHYgE4QdyARhBzJB2IFMEHYgE4QdyARhBzJB2IFMEHYgE4QdyARhBzJB2IFMEHYgE4QdyARhBzJB2IFMEHYgE4QdyARhBzJB2IFMEHYgE4QdyARhBzJB2IFMEHYgE4QdyESlKZttb5O0R9KQpP0R0dOIpgA0XqWwF86MiFca8DoAmojDeCATVcMekh60/bjt3tGeYLvXdp/tvkHtrbg5APWqehh/ekT02z5G0mrbP46ItSOfEBHLJC2TpCM8PSpuD0CdKu3ZI6K/uN0p6X5JpzWiKQCNV3fYbU+zffiB+5I+JWlzoxoD0FhVDuO7Jd1v+8DrfCci/rUhXWHc8Km/WlobOmxSpdeetC09CLT/hRcrvf54U3fYI+J5SSc1sBcATcTQG5AJwg5kgrADmSDsQCYIO5CJRnwRBgexny9MXwf16pz0P5EzPrc+Wb/2mH8urc2aODW5bi23vnpCsv7g+aeU1oa2Pl9p2wcj9uxAJgg7kAnCDmSCsAOZIOxAJgg7kAnCDmSCcfZx7o2LFiTr8ScvJ+tP/tp3K23/B/93TGntoaHDKr32J6b9OFlf/NBTpbVFn12SXDfWb0rWD5l9bLK+/dbDk/UTZ+wsrb12+v8m160Xe3YgE4QdyARhBzJB2IFMEHYgE4QdyARhBzLBOPs4sPMvfqu0dvWV9ybX/f3Dy8d7JenkpVck60f8dChdf/i50trQK9XGk7/ylxcl61+7+hultZ9clB7j//DLv5ysn3T/tmT9b9+X/p7/VVeUv6+TxTg7gAoIO5AJwg5kgrADmSDsQCYIO5AJwg5kwhHRso0d4emxwGe1bHvjxSEnHJesf/YH/1Va+8TU8nFuSbrgy19K1j/wT33JegzuS9abyV3pKZ+f/eZHS2vPnH17ct3/2f9msv7y0KHJ+uW3pK9P6L710WS9XutijXbHLo9Wq7lnt73c9k7bm0csm257te2txe1RjWwYQOON5TD+W5LOecey6yStiYi5ktYUjwF0sJphj4i1kna9Y/FCSSuK+ysknd/YtgA0Wr3XxndHxEBx/yVJ3WVPtN0rqVeSpqja3F4A6lf5bHwMn+ErPcsXEcsioiciero0uermANSp3rDvsD1Tkorb9FenALRdvWFfKWlxcX+xpAca0w6AZqn5md323ZLOkDTD9nZJN0i6SdK9ti+T9IKki5vZZO5+etEvJeuXHflSaW3+36XH0WuN97buKoz37sVre5L1rWf/Y6I66lD02/5866JkffJFryXr3a82Zxy9ipphj4iy/2qujgEOIlwuC2SCsAOZIOxAJgg7kAnCDmSCn5I+CEz67VeS9e37Xy+tda/b0+h23pMJU8svkd514UnJdX/zqvTPMd989NJk/dnB8oHDS265NrnurH/ZnKwP7d6drHci9uxAJgg7kAnCDmSCsAOZIOxAJgg7kAnCDmSCcfaDwK+/fyBZP/M7XyytnfDYf1bb+ISJyfLPf+/UZH3qlf2ltUdP/Hpy3fV701+wXXjf1cn6nGvKf2L7A0p/BTU9EfXBiT07kAnCDmSCsAOZIOxAJgg7kAnCDmSCsAOZYJz9IDD4Vnqs+5NnPVla2zbj6OS6Q7teTdYHrlqQrD95TernmqX9iRHruav/LLnu8Xcly5qzpnwcHe/Gnh3IBGEHMkHYgUwQdiAThB3IBGEHMkHYgUwwzn4QeHT9R5L1r5x3Z2ntprM/n1z3iN4Xk/XbjkuPo//us59J1t9Yemxpbe73H0uui8aquWe3vdz2TtubRyy70Xa/7Q3F33nNbRNAVWM5jP+WpHNGWX5LRMwv/lY1ti0AjVYz7BGxVtKuFvQCoImqnKC7wvbG4jD/qLIn2e613We7b1B7K2wOQBX1hv02SXMkzZc0IKl0hr2IWBYRPRHR06XJdW4OQFV1hT0idkTEUES8Jel2Sac1ti0AjVZX2G3PHPHwAknp+W0BtF3NcXbbd0s6Q9IM29sl3SDpDNvzJYWkbZKWNK9F1PLpqeXzs3966TeS6/7Hm+l/Ajd+/o+T9QmPbEjWp+hnyTpap2bYI2LRKIvvaEIvAJqIy2WBTBB2IBOEHcgEYQcyQdiBTPAV1xaYMGVKsr7r4pOT9bUX/EONLUwtrcx/7A+Sa866+LlkfcLghhrbxsGCPTuQCcIOZIKwA5kg7EAmCDuQCcIOZIKwA5lgnL0Ftn3plGR985L0zzXfteeEZP3Sw18qre3bcmRy3Rjcl6xj/GDPDmSCsAOZIOxAJgg7kAnCDmSCsAOZIOxAJhhnb4CtX1uQrl+YHkf/lbV/lKx/6Ibyn4qWpD3395XWDkvPyIyMsGcHMkHYgUwQdiAThB3IBGEHMkHYgUwQdiATjLOP0RsXlo+lLznzoeS6H/n39LTHH/7izrp6OuA3Dn2+tPbd/qFKr43xo+ae3fZs2z+y/ZTtLba/UCyfbnu17a3F7VHNbxdAvcZyGL9f0jURMU/SxyRdbnuepOskrYmIuZLWFI8BdKiaYY+IgYh4ori/R9LTkmZJWihpRfG0FZLOb1KPABrgPX1mt32cpJMlrZPUHREDReklSd0l6/RK6pWkKYk5yQA015jPxts+TNJ9kq6KiN0jaxERkmK09SJiWUT0RERPlyZXahZA/cYUdttdGg76tyPie8XiHbZnFvWZkqqdUgbQVDUP421b0h2Sno6Im0eUVkpaLOmm4vaBpnTYIfrPLR/Cunb6M8l175l2arK+v/9nyfrEGUcn6xv3zi6tvb7k1eS6U76fLGMcGctn9o9LulTSJtsbimXXazjk99q+TNILki5uSocAGqJm2CPiEUkuKZ/V2HYANAuXywKZIOxAJgg7kAnCDmSCsAOZ4CuuY/S+JyeVF89Nr3vkoW9W2ra7upL1OZN2lNaGHpxR49WfraMjHIzYswOZIOxAJgg7kAnCDmSCsAOZIOxAJgg7kAnG2cdo5g8HSmsP/1V6HPyBeXcn6+evviRZv+yDDyfrJ3a9Vlo75vE3kusiH+zZgUwQdiAThB3IBGEHMkHYgUwQdiAThB3IhIcnc2mNIzw9Fnj8/SDt7s99LFmfd+XmZP3QiYPJ+qrH5ifrcy9fl6wjH+tijXbHrlF/DZo9O5AJwg5kgrADmSDsQCYIO5AJwg5kgrADmag5zm57tqQ7JXVLCknLIuKrtm+U9KeSXi6een1ErEq91ngdZwc6RWqcfSw/XrFf0jUR8YTtwyU9bnt1UbslIr7cqEYBNM9Y5mcfkDRQ3N9j+2lJs5rdGIDGek+f2W0fJ+lkSQeuz7zC9kbby20fVbJOr+0+232D2lutWwB1G3PYbR8m6T5JV0XEbkm3SZojab6G9/xLR1svIpZFRE9E9HRpcvWOAdRlTGG33aXhoH87Ir4nSRGxIyKGIuItSbdLOq15bQKoqmbYbVvSHZKejoibRyyfOeJpF0hKf7ULQFuN5Wz8xyVdKmmT7Q3FsuslLbI9X8PDcdskLWlCfwAaZCxn4x+RNNq4XXJMHUBn4Qo6IBOEHcgEYQcyQdiBTBB2IBOEHcgEYQcyQdiBTBB2IBOEHcgEYQcyQdiBTBB2IBOEHchES6dstv2ypBdGLJoh6ZWWNfDedGpvndqXRG/1amRvH4yI949WaGnY37Vxuy8ietrWQEKn9tapfUn0Vq9W9cZhPJAJwg5kot1hX9bm7ad0am+d2pdEb/VqSW9t/cwOoHXavWcH0CKEHchEW8Ju+xzbz9h+zvZ17eihjO1ttjfZ3mC7r829LLe90/bmEcum215te2txO+oce23q7Ubb/cV7t8H2eW3qbbbtH9l+yvYW218olrf1vUv01ZL3reWf2W1PlPSspE9K2i5pvaRFEfFUSxspYXubpJ6IaPsFGLZ/R9Lrku6MiI8Wy/5e0q6IuKn4H+VREfHXHdLbjZJeb/c03sVsRTNHTjMu6XxJf6g2vneJvi5WC963duzZT5P0XEQ8HxH7JN0jaWEb+uh4EbFW0q53LF4oaUVxf4WG/7G0XElvHSEiBiLiieL+HkkHphlv63uX6Ksl2hH2WZJeHPF4uzprvveQ9KDtx233truZUXRHxEBx/yVJ3e1sZhQ1p/FupXdMM94x7109059XxQm6dzs9Ik6RdK6ky4vD1Y4Uw5/BOmnsdEzTeLfKKNOMv62d7129059X1Y6w90uaPeLxscWyjhAR/cXtTkn3q/Omot5xYAbd4nZnm/t5WydN4z3aNOPqgPeundOftyPs6yXNtX287UmSLpG0sg19vIvtacWJE9meJulT6rypqFdKWlzcXyzpgTb28gs6ZRrvsmnG1eb3ru3Tn0dEy/8knafhM/I/kfQ37eihpK8TJP138bel3b1JulvDh3WDGj63cZmkoyWtkbRV0r9Jmt5Bvd0laZOkjRoO1sw29Xa6hg/RN0raUPyd1+73LtFXS943LpcFMsEJOiAThB3IBGEHMkHYgUwQdiAThB3IBGEHMvH/YbpO1uZsJw0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "image = np.asarray(X_train[59999]).squeeze()\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "y_train[59999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "extensive-muscle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "lovely-amount",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28, 1)\n",
      "(10000, 10)\n",
      "(10000, 28, 28, 1)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "X_train = X_train.reshape(10000,28,28,1)\n",
    "print(X_train.shape)\n",
    "# y_train = y_train[0:10000]\n",
    "y_train = dummies(10, y_train)\n",
    "print(y_train.shape)\n",
    "\n",
    "# Testing data\n",
    "X_test = X_test.reshape(10000,28,28,1)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fresh-privilege",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "periodic-being",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-naples",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-viewer",
   "metadata": {},
   "source": [
    "### Set up the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-income",
   "metadata": {},
   "source": [
    "## Visualisation of the model just built\n",
    "\n",
    "![](Image/Image6.jpg)\n",
    "\n",
    "1. One Image input (28 * 28 pixels) are passed into a convolution layer (10 neurons). \n",
    "2. Then the output feature map is flatten by Flatten layer \n",
    "3. The flatten feature map is passed into the output layer (Dense with 10 neurons --> 10 output classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "empty-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(10, kernel_size = 3, activation = 'relu', input_shape = (28, 28, 1)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(10, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "brown-berkeley",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-gazette",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "appointed-asset",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/2\n",
      "4000/4000 [==============================] - 2s 560us/step - loss: nan - accuracy: 0.0938 - val_loss: nan - val_accuracy: 0.1000\n",
      "Epoch 2/2\n",
      "4000/4000 [==============================] - 1s 247us/step - loss: nan - accuracy: 0.0948 - val_loss: nan - val_accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21596218248>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Set up Early Stopping Monitor\n",
    "early_stopping_monitor = EarlyStopping(patience = 2)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_split = 0.2, epochs = 2, callbacks = [early_stopping_monitor], batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "reverse-meeting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "wanted-garden",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "extended-washington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 9., 0., 6., 9., 0., 1., 5., 9., 7., 3., 4., 9., 6., 6., 5., 4.,\n",
       "       0., 7., 4.], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-warner",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-saint",
   "metadata": {},
   "source": [
    "# Tweaking the convolution model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-transfer",
   "metadata": {},
   "source": [
    "## Zero Padding methodology\n",
    "\n",
    "![](Image/Kernel1.jpg)\n",
    "\n",
    "由上圖可發現，Feature map的size = 2 * 2，然而原本的image的size = 4 * 4，這是因為kernel的size = 3 * 3 <br/>\n",
    "如果每次用kernel都會使size減少，這樣會限制convolution layers的數量\n",
    "\n",
    "為了讓Feature map和image的size一致，可以用**Zero Padding**方法：\n",
    "\n",
    "將原本的image外面包一層數值為0的pixel，如下圖 (以size = 5的image表示)：\n",
    "\n",
    "![](Image/Image7.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-detector",
   "metadata": {},
   "source": [
    "### Zero Padding in Keras\n",
    "\n",
    "padding = 'valid' 代表沒有加入zero padding (default) <br/>\n",
    "padding = 'same' 代表前一層會加入zero padding，因此這一層的size = 前一層的size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adult-hardwood",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(10, kernel_size = 3, activation = 'relu', input_shape = (28, 28, 1), padding = 'same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(10, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indie-burner",
   "metadata": {},
   "source": [
    "## Kernel Stride (大步走)\n",
    "\n",
    "kernel在image上移動時，不一定要一個pixel一個pixel這樣掃，可能會太久，因此可以調整kernel一次移動的距離 <br/>\n",
    "也是可以在Convonlution layer透過傳入Argument來調整 <br/>\n",
    "strides = 1為default，代表step size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "informative-detail",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(10, kernel_size = 3, activation = 'relu', input_shape = (28, 28, 1), strides = 2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(10, activation = 'relu'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adopted-mounting",
   "metadata": {},
   "source": [
    "Kernel一次跨過多個pixels也代表其輸出的feature map的size會比原image小\n",
    "\n",
    "![](Image/Image8.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-pioneer",
   "metadata": {},
   "source": [
    "## Size of the output feature map\n",
    "\n",
    "Formula:\n",
    "$$O = ((I - K + 2P)/S) + 1$$\n",
    "\n",
    "Where <br/>\n",
    "I = size of the input <br/>\n",
    "K = size of the kernel <br/>\n",
    "P = size of the zero padding <br/>\n",
    "S = strides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-colombia",
   "metadata": {},
   "source": [
    "## Dilated Convolution\n",
    "\n",
    "The spacing between the pixels affected by the kernel\n",
    "\n",
    "![](Image/Image9.jpg)\n",
    "\n",
    "這時，雖然kernel的size = 3 * 3，但是卻能大致涵蓋了跟size = 5 * 5的kernel一樣的面積 <br/>\n",
    "同樣的，也可以透過Convolution layer中的argument來調整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "impressive-stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(10, kernel_size = 3, activation = 'relu', input_shape = (28, 28, 1), dilation_rate = 2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(10, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-ireland",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
